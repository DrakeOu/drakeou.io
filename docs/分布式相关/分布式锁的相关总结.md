# 分布式锁的相关总结

总所周知阿，分布式锁一般使用三种方式进行实现，`Zookeeper`，`Redis`和`MySQL`

这里对三种方法的具体实现和锁相关的一些问题进行总结以便日后查阅



## Zookeeper实现分布式锁

zk作为分布式协调工具，支持但不限于以下功能：

- 服务注册与订阅（共用节点）
- 分布式通知（监听节点znode）
- 服务命名（znode特性）
- 数据订阅、发布（watcher）
- 分布式锁（临时节点）

zk的节点类型按持久型，临时型和是否按顺序划分成4类节点：

- 持久化节点
- 持久化顺序节点
- 临时目录节点
- 临时目录顺序节点

那么实现一个分布式锁就可以利用zk节点的唯一性，比如我们通过`create /zk_abtest`就可以创建一个名为`zk_abtest`的持久节点，而尝试创建的客户端将报错无法创建。

那么这样zk的加锁功能就实现了，而获取锁失败的一方需要有方式得知锁已经被释放了（节点被删除），所以这里利用**zk可以注册事件监听的功能**去监听**节点的删除事件**。

同样的，获取了锁最后需要对锁进行释放，所以调用方需要在`finally`这样的语句中进行节点的删除（类似平时使用Lock时的try finally模板）。

而考虑到持有锁的机器可能临时宕机了，节点不能被正确的删除，出现死锁。所以**应该使用临时节点作为锁的实现**，因为zk中创建临时节点的客户端会话断开后节点会被集群自动删除，这样就保证了即使宕机也不会出现死锁。

除此之外，等待方需要实现阻塞的效果，因为拿不到锁就阻塞🐎。所以简单的方案来说可以使用轮询的方式模拟阻塞，当然这些都是封装在锁的工具之中的。

而且类比使用Object.wait(), notifyAll()这样的实现锁的方式存在的虚假唤醒的问题，zk对临时节点的监听也存在同样的问题，因为zk不知道这个节点实现的是锁功能，会将事件广播到所有锁的等待者上，但实际上只会有一个客户端成功创建节点，这样也产生了羊群效应，唤醒了大量的机器但只有极少的有效唤醒，浪费网络带宽和服务资源。这个问题上就考虑使用zk的顺序节点，zk的顺序节点实现是每个监听特定节点的客户端都会在前者的基础上创建一个顺序节点，每个节点都值监听前一个节点，这样就可以保证节点的顺序唤醒。

### ZK作为分布式锁实现的一些缺点

- 性能不如缓存服务，每次锁的创建和释放都意味着节点的创建和删除
- 节点的创建删除只能在ZK的leader节点上进行，这意味着当我们通过非leader节点创建锁时，在集群内部是存在流量转发的，性能不会特别好
- 在上面说到临时节点在会话断开时会被删除，这就存在zk客户端因为网络抖动而导致连接断开，丢失锁的情况，其实稍后网络恢复有建立的连接，但此时锁也被分配到了其他机器上，导致多台机器同时获取到了锁，产生并发问题。当然在zk自身的会话心跳及重连机制下，这个问题时比较少见的

### 锁

其实从上面用zk来实现分布式锁可以看出实现锁功能的一些通用性的点

1. **对于锁的获取必须是原子性的**。获取锁是可以确保对临界资源的操作是安全的，而这个状态开始于对锁的获取，所以锁的获取方式必须是原子性的操作，否则每个人都可以拿到锁，那锁也没有任何意义。对于zk而言，创建节点就是原子性的，对于ReentrantLock而言lock.lock()就是对底层volatile变量的CAS访问。
2. **锁都需要在没有程序没有崩溃时可以正常地释放**。try finally便是这么个含义，程序出现了异常但没有崩溃，所以在程序范围内都可以保证锁的释放。而分布式锁中，兜底的程序是zk，所以要确保zk上可以正常释放锁，那么finally可能就不够了，因为此时的锁竞争方并不在一台机器上，机器的宕机会产生不一致的影响，那么临时节点可以解决这种问题，保证宕机的情况也可以释放锁。
3. **等待锁的一方需要阻塞**
4. **要可以通知到等待锁的一方**
5. **尽量使用顺序唤醒，避免羊群效应或虚假唤醒**，顺序唤醒这里涉及到的是公平或非公平锁的区别。



### 分布式事务出现问题时如何影响锁





## Redis实现分布式锁



### 单机实现

最简单的方式可以考虑使用一个String的key来表示锁，获取锁时检查key是否存在，不存在则创建**指定名称的key**，存在则表明被其他客户端加锁了，需要阻塞等待。

#### 加锁操作必须是原子性的

如果这里的锁获取操作是采用先`exist key`再`set key`的方式话是不可行的，因为这两个操作各自是原子性的但是组合成一个操作显然不保证原子性，可以考虑使用`SETNX`这样的原子性指令实现，则可以保证**加锁操作的原子性**。

#### 分布式要考虑宕机锁的释放

然后再是考虑到获取锁的服务器宕机的情况，如果宕机了那么锁就不会被主动删除了，所以可以使用`SETNX`加上过期时间，这样**可以保证锁的稳定释放**。

#### 超时释放的问题

另外的，考虑如果锁的使用时长大于超时时长，那么可能导致两个问题：

1. 锁还没有使用完，就已经被其他人获取了
2. 锁真正使用完时，去删除key以释放锁，但此时的锁被别人持有，自己删除了别人的锁。

所以为了防止**操作其他人的锁**，在获取锁时携带一个根据自身计算出的UUID或者其他标识，作为key的值，在删除锁操作时通过`get key`检查值，而之后再`del key`的方式确保不会误操作其他人的锁。

#### 使用Lua脚本保证原子性

而上面这种方式也是显然存在和开头方法一样的问题，**不是原子性**，仍然会出现先通过了`get key`的检查随后其他客户端获取锁，然后因为自身已经通过了验证，对其他客户端的锁进行了误删除。

最后这种方式实际上出现的原因是没有解决，**锁没有使用完，但被超时释放**这个问题。如果需要最后删除的操作为原子性，那么可以使用**Lua脚本**，所有Redis自身没有提供原子性的操作都可以通过Lua脚本来保证其原子性。（解决了超时释放带来的问题之一，但没有解决超时释放的问题）

#### 解决锁被提前释放的问题

为了解决上面这个问题可以使用`Redission`框架，其使用了**一个daemon线程，每隔一段实际检测锁的存在，并对存在的锁进行延长超时**。

架构如下

![v2-af1fecc039bc40696f02eb64253d873c_720w](..\static\Distribute\v2-af1fecc039bc40696f02eb64253d873c_720w.jpg)

只要线程一加锁成功，就会启动一个watch dog看门狗，它是一个后台线程，会每隔10秒检查一下，如果线程1还持有锁，那么就会不断地延长锁key的生存时间。因此，Redisson就是使用Redisson解决了「锁过期释放，业务没执行完」问题。

### 集群实现

