# TCP疑点汇总

TCP的问题主要在这么几点：

1. 网络连接的可靠保证（三握四挥）
2. 数据传输的可靠保证（超时重传）
3. 对网络环境公平性的保证（拥塞控制）
4. 传输的流量控制（滑动窗口）



## 三次握手，四次挥手

贴下整个流程的状态机图

![105123g2lejy56ffwyeyef](..\static\TCP\105123g2lejy56ffwyeyef.jpg)



![105155l9egwdbkzd478cdy](..\static\TCP\105155l9egwdbkzd478cdy.jpg)

这个流程确实没有什么可以赘述的，主要是不要忘记每个状态的名字

- `Fin_Wait_1`：断开连接过程中，主动方发送`Fin`之后，等待对方`ACK`自己的请求的状态。这个状态是等待己方通信信道的断开完成。

- `Fin_Wait_2`：在主动方收到对方对自己`FIN`的`ACK`后，等待对方发起`FIN`时的状态。这个状态是己方已经断开了到被动方的单向信道后等待被动方发起断开`FIN`的过程。

- `TIME-WAIT`：在等到被动方发起的`FIN`之后将开始关闭连接`CLOSING`，发送`ACK`后进入这个状态。此状态是确保被动方的连接可以被可靠关闭，因为TCP的协议规范，不对`ACK`进行`ACK`，所以此时的`TIME-WAIT`等待方无法验证自己的`ACK`是否被收到，只有`FIN`的发送方可以通过`ACK`来确认自己的`FIN`是否被送达。

  这里听起来有点绕，但实际上确实如此，**超时重试的基础其实不是超时重发，而是凭借什么来确认流程正常无需超时**，所以主动方在接收到被动方发起的`FIN`请求后，也只能进行`2*MSL`时间的等待，来保证如果自己的`ACK`丢失了，还能接收到对方重试发来的`FIN`。（确保被动方连接的可靠断开）

  同样的，不论被动方的`FIN`包发送过程如何，在主动方进入`TIME_WAIT`状态后，两个MSL时间是网络空间中可能还存在`FIN`的最长时长。如果不等待，对方没有接收到`FIN`的`ACK`，进行重试，主动方会发现连接已经完全关闭，目前根本没有建立连接，会直接回一个`RST`重置连接，那么这将导致被动方报错``Connect rest by peer`，所以需要等待避免这种情况(**不等待对别人有什么后果**)；同样的，在这个时间内新建立的连接可能复用了之前连接的5个元素（源IP，目的IP，TCP，源端口，目的端口），导致新的连接被重试的`FIN`给错误关闭（**不等待对自己有什么后果**）。

  

### 各种疑点

#### TCP 连接的初始化序列号能否固定

（固定的序列号可能会使先后不同的连接相互影响）

**如果初始化序列号（缩写为ISN：Inital Sequence Number）可以固定，我们来看看会出现什么问题：**

- 假设ISN固定是1，Client和Server建立好一条TCP连接后，Client连续给Server发了10个包，这10个包不知怎么被链路上的路由器缓存了(路由器会毫无先兆地缓存或者丢弃任何的数据包)，这个时候碰巧Client挂掉了；
- 然后Client用同样的端口号重新连上Server，Client又连续给Server发了几个包，假设这个时候Client的序列号变成了5；
- 接着，之前被路由器缓存的10个数据包全部被路由到Server端了，Server给Client回复确认号10，这个时候，Client整个都不好了，这是什么情况？我的序列号才到5，你怎么给我的确认号是10了，整个都乱了。


[RFC793](https://tools.ietf.org/html/rfc793)中，建议ISN和一个假的时钟绑在一起，这个时钟会在每4微秒对ISN做加一操作，直到超过2^32，又从0开始，这需要4小时才会产生ISN的回绕问题，这几乎可以保证每个新连接的ISN不会和旧的连接的ISN产生冲突。这种递增方式的ISN，很容易让攻击者猜测到TCP连接的ISN，现在的实现大多是在一个基准值的基础上进行随机的。

#### TCP 的 Peer 两端同时断开连接

**由上面的“TCP协议状态机 ”图可以看出：**



- TCP的Peer端在收到对端的FIN包前发出了FIN包，那么该Peer的状态就变成了FIN_WAIT1；
- Peer在FIN_WAIT1状态下收到对端Peer对自己FIN包的ACK包的话，那么Peer状态就变成FIN_WAIT2；
- Peer在FIN_WAIT2下收到对端Peer的FIN包，在确认已经收到了对端Peer全部的Data数据包后，就响应一个ACK给对端Peer，然后自己进入TIME_WAIT状态。


但是如果Peer在FIN_WAIT1状态下首先收到对端Peer的FIN包的话，那么该Peer在确认已经收到了对端Peer全部的Data数据包后，就响应一个ACK给对端Peer，然后自己进入CLOSEING状态，Peer在CLOSEING状态下收到自己的FIN包的ACK包的话，那么就进入TIME WAIT 状态。于是，TCP的Peer两端同时发起FIN包进行断开连接，那么两端Peer可能出现完全一样的状态转移 FIN_WAIT1-->CLOSEING-->TIME_WAIT，也就会Client和Server最后同时进入TIME_WAIT状态。

#### TCP中的超时

所有超时重试的功能都会维护一个队列或者至少使用计时器并占用内存，而这段超时时间就会给攻击者耗尽服务器资源的时间和操作空间。

- SYN-REVD维护的半连接队列：服务端会对半连接进行指数退避的重试策略。对应SYN flood攻击，应对攻击策略
- TIME-WAIT：

#### TIME-WAIT的快速回收和重复使用

##### TIME_WAIT快速回收


linux下开启TIME_WAIT快速回收需要同时打开`tcp_tw_recycle`和`tcp_timestamps`(默认打开)两选项。Linux下快速回收的时间为3.5 * RTO（Retransmission Timeout），而一个RTO时间为200ms至120s。开启快速回收TIME_WAIT，可能会带来不进行TIME_WAIT中说的三点危险。

**为了避免这些危险，要求同时满足以下三种情况的新连接要被拒绝掉：**



- 1）来自同一个对端Peer的TCP包携带了时间戳；
- 2）之前同一台peer机器(仅仅识别IP地址，因为连接被快速释放了，没了端口信息)的某个TCP数据在MSL秒之内到过本Server；
- 3）Peer机器新连接的时间戳小于peer机器上次TCP到来时的时间戳，且差值大于重放窗口戳(TCP_PAWS_WINDOW)。初看起来正常的数据包同时满足下面3条几乎不可能， 因为机器的时间戳不可能倒流的，出现上述的3点均满足时，一定是老的重复数据包又回来了，丢弃老的SYN包是正常的。到此，似乎启用快速回收就能很大程度缓解TIME_WAIT带来的问题。但是，这里忽略了一个东西就是NAT。。。在一个NAT后面的所有Peer机器在Server看来都是一个机器，NAT后面的那么多Peer机器的系统时间戳很可能不一致，有些快，有些慢。这样，在Server关闭了与系统时间戳快的Client的连接后，在这个连接进入快速回收的时候，同一NAT后面的系统时间戳慢的Client向Server发起连接，这就很有可能同时满足上面的三种情况，造成该连接被Server拒绝掉。所以，在是否开启tcp_tw_recycle需要慎重考虑了。



##### TIME_WAIT重用


linux上比较完美的实现了TIME_WAIT重用问题。只要满足下面两点中的一点，一个TW状态的四元组(即一个socket连接)可以重新被新到来的SYN连接使用：



- 1）新连接SYN告知的初始序列号比TIME_WAIT老连接的末序列号大；
- 2）如果开启了tcp_timestamps，并且新到来的连接的时间戳比老连接的时间戳大。


要同时开启`tcp_tw_reuse`选项和`tcp_timestamps` 选项才可以开启TIME_WAIT重用，还有一个条件是：重用TIME_WAIT的条件是收到最后一个包后超过1s。细心的同学可能发现TIME_WAIT重用对Server端来说并没解决大量TIME_WAIT造成的资源消耗的问题，因为不管TIME_WAIT连接是否被重用，它依旧占用着系统资源。即便如此，TIME_WAIT重用还是有些用处的，它解决了整机范围拒绝接入的问题，虽然一般一个单独的Client是不可能在MSL内用同一个端口连接同一个服务的，但是如果Client做了bind端口那就是同个端口了。时间戳重用TIME_WAIT连接的机制的前提是IP地址唯一性，得出新请求发起自同一台机器，但是如果是NAT环境下就不能这样保证了，于是在NAT环境下，TIME_WAIT重用还是有风险的。

有些同学可能会混淆`tcp_tw_reuse`和`SO_REUSEADDR` 选项，认为是相关的一个东西，其实他们是两个完全不同的东西，可以说两个半毛钱关系都没。`tcp_tw_reuse`是内核选项，而`SO_REUSEADDR`用户态的选项，使用`SO_REUSEADDR`是告诉内核，如果端口忙，但TCP状态位于 TIME_WAIT ，可以重用端口。如果端口忙，而TCP状态位于其他状态，重用端口时依旧得到一个错误信息， 指明Address already in use”。如果你的服务程序停止后想立即重启，而新套接字依旧使用同一端口，此时 `SO_REUSEADDR` 选项非常有用。但是，使用这个选项就会有上述的三点危险，虽然发生的概率不大。

## 超时重传

重传分为两个讨论的问题

1. 重传的超时计算
2. 重传的机制

TCP的重传简单来说是基于时间驱动进行的，必须等待一个超时时间，无法对网络做出快速响应。而快速重传是一个以数据驱动为方式的算法，可以解决这个Timeout的问题，如果连续收到三个一样的ACK，那么就进行重传。

但TCP的ACK有这样的特性：

- 考虑到延迟确认，ACK会按当前收到的最大序列号进行ACK，表示小于这个值的包都全部收到。所以确认是批量确认的。
- 包的发送范围是由滑动窗口决定的（其实还有拥塞控制窗口的共同作用），如果后面的包不是连续的，有丢包，那么接收到的ACK只可能是对方接收到的连续包的最大值

所以重传的时候，可以明确知道丢包了，且知道丢的第一个包，但不能知道到底丢了多少包。

**于是，RFC2018提出了Selective Acknowledgment (SACK，选择确认)机制，SACK是TCP的扩展选项，包括：**

- 1）SACK允许选项（Kind=4,Length=2，选项只允许在有SYN标志的TCP包中）；
- 2）SACK信息选项（Kind=5,Length）。
  一个SACK的例子如下图，红框说明：接收端收到了0-5500，8000-8500，7000-7500，6000-6500的数据了，这样发送端就可以选择重传丢失的5500-6000，6500-7000，7500-8000的包：

![不为人知的网络编程(二)：浅析TCP协议中的疑难杂症(下篇)_2.jpg](http://www.52im.net/data/attachment/forum/201708/30/145735pwc9ccjvx96gvqnu.jpg)



SACK依靠接收端的接收情况反馈，解决了重传风暴问题，这样够了吗？接收端能不能反馈更多的信息呢？显然是可以的，于是，RFC2883对对SACK进行了扩展，提出了D-SACK，也就是利用第一块SACK数据中描述重复接收的不连续数据块的序列号参数，其他SACK数据则描述其他正常接收到的不连续数据。这样发送方利用第一块SACK，可以发现数据段被网络复制、错误重传、ACK丢失引起的重传、重传超时等异常的网络状况，使得发送端能更好调整自己的重传策略。

**D-SACK，有几个优点：**

- 1）发送端可以判断出，是发包丢失了，还是接收端的ACK丢失了。(发送方，重传了一个包，发现并没有D-SACK那个包，那么就是发送的数据包丢了；否则就是接收端的ACK丢了，或者是发送的包延迟到达了)；
- 2）发送端可以判断自己的RTO是不是有点小了，导致过早重传(如果收到比较多的D-SACK就该怀疑是RTO小了)；
- 3）发送端可以判断自己的数据包是不是被复制了。(如果明明没有重传该数据包，但是收到该数据包的D-SACK)；
- 4）发送端可以判断目前网络上是不是出现了有些包被delay了，也就是出现先发的包却后到了。

由上可以看出**重传机制的发展过程**

1. 简单的超时作为唯一因素
2. 使用**快速重传**引入数据因素解决单纯超时的被动局面
3. 使用`Selective Acknowladge`解决重传时的重传风暴问题（因为不知道需要重传多少，要么一条一条重传，要么丢包后的全部重传）
4. 使用`D-SACK`增强信息传递